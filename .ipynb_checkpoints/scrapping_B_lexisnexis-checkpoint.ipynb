{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from: http://yc-lexisnexis-scraper.readthedocs.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-4609d677146f>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-4609d677146f>\"\u001b[1;36m, line \u001b[1;32m27\u001b[0m\n\u001b[1;33m    _RE_STYLESHEET = re.compile(ur'\\<STYLE TYPE\\=\\\"text\\/css\\\"\\>(\\<\\!\\-\\-)?(?P<css_string>.+?)(\\-\\-\\>)?\\<\\/STYLE\\>', flags=re.S | re.U | re.I)\u001b[0m\n\u001b[1;37m                                                                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import requests\n",
    "import urllib\n",
    "import urlparse\n",
    "\n",
    "import selenium.common.exceptions\n",
    "import selenium.webdriver\n",
    "import selenium.webdriver.common.desired_capabilities\n",
    "import selenium.webdriver.support.ui\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "\n",
    "\n",
    "class LexisNexisScraper:\n",
    "  \"\"\"\n",
    "  Class for downloading documents given a query string to Lexis Nexis academic (http://www.lexisnexis.com/hottopics/lnacademic/).\n",
    "\n",
    "  Example::\n",
    "\n",
    "      downloader = LexisNexisScraper(mass_download_mode=True)\n",
    "      for (content, (doc_index, doc_count)) in downloader.iter_search_results(6318, 'DATE(=1987)'):\n",
    "        print doc_id\n",
    "\n",
    "  This code uses `PhantomJS <http://phantomjs.org>`__ and `Selenium Webdriver <http://www.seleniumhq.org/>`__ to scrape LexisNexis pages.\n",
    "  \"\"\"\n",
    "\n",
    "  _RE_STYLESHEET = re.compile(ur'\\<STYLE TYPE\\=\\\"text\\/css\\\"\\>(\\<\\!\\-\\-)?(?P<css_string>.+?)(\\-\\-\\>)?\\<\\/STYLE\\>', flags=re.S | re.U | re.I)\n",
    "  _RE_LEXIS_DOC = re.compile(ur'\\<DOC NUMBER\\=(?P<docid>\\d+)\\>\\s+\\<DOCFULL\\>(?P<doc>.+?)\\<\\/DOCFULL\\>', flags=re.S | re.U | re.I)\n",
    "\n",
    "  def __init__(self, wait_timeouts=(15, 180), documents_per_download=(250, 500), user_agent_string=u'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0', mass_download_mode=False):\n",
    "    \"\"\"\n",
    "    Constructs a downloader object.\n",
    "\n",
    "    :param float,float wait_timeouts: tuple of `(short, long)` where `short` and `long` are the no. of seconds to wait while page elements are loaded (for Webdriver). `long` timeout is used when waiting for LexisNexis to format documents for mass downloads.\n",
    "    :param int,int documents_per_download: a range specifying the number of documents to download each time when using :attr:`mass_download_mode`.\n",
    "    :param str user_agent_string: the user agent string that PhantomJS should declare itself to be.\n",
    "    :param bool mass_download_mode: whether to mass download articles using the download link or page through each document one by one and download.\n",
    "    \"\"\"\n",
    "\n",
    "    self._USER_AGENT_STRING = user_agent_string\n",
    "    self._DOCUMENTS_PER_DOWNLOAD = documents_per_download\n",
    "\n",
    "    desired_capabilities = dict(selenium.webdriver.common.desired_capabilities.DesiredCapabilities.PHANTOMJS)\n",
    "    desired_capabilities['phantomjs.page.settings.userAgent'] = self._USER_AGENT_STRING\n",
    "\n",
    "    self._driver = selenium.webdriver.PhantomJS(desired_capabilities=desired_capabilities)\n",
    "    self._driver.set_window_size(800, 600)\n",
    "\n",
    "    self._short_wait = selenium.webdriver.support.ui.WebDriverWait(self._driver, wait_timeouts[0], poll_frequency=0.05)\n",
    "    self._long_wait = selenium.webdriver.support.ui.WebDriverWait(self._driver, wait_timeouts[1], poll_frequency=1)\n",
    "\n",
    "    self.mass_download_mode_ = mass_download_mode\n",
    "  #end def\n",
    "\n",
    "  def __del__(self):\n",
    "    try: self._driver.quit()\n",
    "    except: pass\n",
    "\n",
    "  def iter_search_results(self, csi, search_query, start_from=1):\n",
    "    \"\"\"\n",
    "    A generator function that executes LexisNexis search query on source data CSI (:attr:`csi`), with query :attr:`search_query` and downloads all documents returned by search.\n",
    "\n",
    "    :param str csi: LexisNexis CSI (see `<http://amdev.net/rpt_download.php>`_ for full list).\n",
    "    :param str search_query: execute search query string.\n",
    "    :param int start_from: document index to start downloading from.\n",
    "    :returns: a tuple `(doc_content, (index, results_count))`, where `doc_content` is the HTML content of the `index`th document, and `results_count` is the number of documents returned by specified search query.\n",
    "    \"\"\"\n",
    "\n",
    "    self._driver.get('http://www.lexisnexis.com/hottopics/lnacademic/?' + urllib.urlencode({'verb': 'sr', 'csi': csi, 'sr': search_query}))\n",
    "    if not self._have_results(): return []\n",
    "\n",
    "    if self.mass_download_mode_: return self._mass_download(start_from)\n",
    "    return self._sequential_download(start_from)\n",
    "  #end def\n",
    "\n",
    "  def _have_results(self):  # todo: kinda slow, due to having wait for multiple timeouts\n",
    "    self._switch_to_frame('main')\n",
    "    if self._wait_for_element('//td[text()[contains(., \\'No Documents Found\\')]]', raise_error=False) is not None: return False\n",
    "    if self._wait_for_element('//frame[@title=\\'Results Content Frame\\']', raise_error=False) is not None: return True\n",
    "    if self._wait_for_element('//frame[@title=\\'Results Document Content Frame\\']', raise_error=False) is not None: return True\n",
    "\n",
    "    raise Exception('Page loaded improperly while checking for results frame.')\n",
    "  #end def\n",
    "\n",
    "  def _mass_download(self, start_from=1):  # Returns documents as a list of strings containing HTML\n",
    "    self._switch_to_frame('navigation')\n",
    "\n",
    "    try: documents_count = int(self._driver.find_element_by_xpath('//form[@name=\\'results_docview_DocumentForm\\']/input[@name=\\'totalDocsInResult\\']').get_attribute('value'))\n",
    "    except: documents_count = -1\n",
    "\n",
    "    def download_sequence(start, end):\n",
    "      docs_left = end - start + 1\n",
    "      cur = start\n",
    "      while docs_left > self._DOCUMENTS_PER_DOWNLOAD[1]:\n",
    "        download_count = random.randint(*self._DOCUMENTS_PER_DOWNLOAD)\n",
    "        yield (cur, cur + download_count - 1)\n",
    "        docs_left -= download_count\n",
    "        cur += download_count\n",
    "      #end while\n",
    "\n",
    "      yield (cur, cur + docs_left - 1)\n",
    "    #end def\n",
    "\n",
    "    def lexis_nexis_download_window_appears(current_handle):\n",
    "      def f(driver):\n",
    "        for handle in driver.window_handles:\n",
    "          if current_handle != handle:\n",
    "            driver.switch_to.window(handle)  # switch first to check window title\n",
    "            if driver.title.endswith('Download Documents'): return True  # this is our new window!\n",
    "          #end if\n",
    "        #end for\n",
    "\n",
    "        return False\n",
    "      #end def\n",
    "\n",
    "      return f\n",
    "    #end class\n",
    "\n",
    "    for download_start, download_end in download_sequence(start_from, documents_count):\n",
    "      self._switch_to_frame('navigation')\n",
    "\n",
    "      parent_window_handle = self._driver.current_window_handle\n",
    "\n",
    "      # check for download icon and click it\n",
    "      self._wait_for_element('//img[@title=\\'Download Documents\\']').click()\n",
    "\n",
    "      # wait for download window to appear\n",
    "      self._short_wait.until(lexis_nexis_download_window_appears(parent_window_handle))\n",
    "      self._wait_for_element('//img[@title=\\'Download\\']')\n",
    "\n",
    "      # get all the form items\n",
    "      selenium.webdriver.support.ui.Select(self._driver.find_element_by_xpath('//select[@name=\\'delFmt\\']')).select_by_value('QDS_EF_HTML')\n",
    "      selenium.webdriver.support.ui.Select(self._driver.find_element_by_xpath('//select[@name=\\'delView\\']')).select_by_value('GNBFI')\n",
    "      selenium.webdriver.support.ui.Select(self._driver.find_element_by_xpath('//select[@name=\\'delFontType\\']')).select_by_value('COURIER')  # i like courier\n",
    "\n",
    "      search_term_bold = self._driver.find_element_by_xpath('//input[@type=\\'checkbox\\'][@id=\\'termBold\\']')\n",
    "      if not search_term_bold.is_selected(): search_term_bold.click()\n",
    "      doc_new_page = self._driver.find_element_by_xpath('//input[@type=\\'checkbox\\'][@id=\\'docnewpg\\']')\n",
    "      if not doc_new_page.is_selected(): doc_new_page.click()\n",
    "\n",
    "      self._driver.find_element_by_xpath('//input[@type=\\'radio\\'][@id=\\'sel\\']').click()\n",
    "      self._driver.find_element_by_xpath('//input[@type=\\'text\\'][@id=\\'rangetextbox\\']').send_keys('{}-{}'.format(download_start, download_end))\n",
    "\n",
    "      self._driver.find_element_by_xpath('//img[@title=\\'Download\\']').click()\n",
    "\n",
    "      download_url = self._long_wait.until(expected_conditions.presence_of_element_located((selenium.webdriver.common.by.By.XPATH, '//center[@class=\\'suspendbox\\']/p/a'))).get_attribute('href')\n",
    "\n",
    "      # set up cookies and use requests library to do download\n",
    "      cookies = dict([(cookie['name'], cookie['value']) for cookie in self._driver.get_cookies()])\n",
    "      response = requests.get(download_url, cookies=cookies, headers={'User-Agent': self._USER_AGENT_STRING})\n",
    "      html_content = response.text\n",
    "\n",
    "      m = self._RE_STYLESHEET.search(html_content)\n",
    "      css_string = m.group('css_string').strip()\n",
    "\n",
    "      for i, m in enumerate(self._RE_LEXIS_DOC.finditer(html_content)):\n",
    "        page_content = m.group('doc').replace(u'<!-- Hide XML section from browser', '').replace(u'-->', '').strip()\n",
    "        page_content = u'\\n'.join([u'<HTML>', u'<HEAD>', u'<STYLE TYPE=\\\"text/css\\\">', css_string, u'</STYLE>', u'</HEAD>', u'<BODY>', page_content, u'</BODY>', u'</HTML>'])\n",
    "\n",
    "        yield (page_content, (download_start + i, documents_count))\n",
    "      #end for\n",
    "\n",
    "      self._driver.close()\n",
    "      self._driver.switch_to.window(parent_window_handle)\n",
    "    #end for\n",
    "  #end def\n",
    "\n",
    "  def _sequential_download(self, start_from=1):\n",
    "    self._switch_to_frame('navigation')\n",
    "    try: documents_count = int(self._driver.find_element_by_xpath('//form[@name=\\'results_docview_DocumentForm\\']/input[@name=\\'totalDocsInResult\\']').get_attribute('value'))\n",
    "    except: documents_count = -1\n",
    "    if documents_count <= 0: return\n",
    "\n",
    "    if start_from > documents_count: return\n",
    "\n",
    "    if documents_count == 1:\n",
    "      self._switch_to_frame('content')\n",
    "      page_content = self._driver.page_source\n",
    "      yield (page_content, (1, 1))\n",
    "      return\n",
    "    #end if\n",
    "\n",
    "    self._switch_to_frame('results')  # go to results list and grab the first link\n",
    "    first_document_url = self._wait_for_element('//td/a[contains(@href, \\'/lnacui2api/results/docview/docview.do\\')]').get_attribute('href')\n",
    "\n",
    "    url_obj = urlparse.urlparse(first_document_url)\n",
    "    qs_dict = dict(urlparse.parse_qsl(url_obj.query))\n",
    "    qs_dict['docNo'] = start_from\n",
    "    doc_url = urlparse.urlunparse((url_obj.scheme, url_obj.netloc, url_obj.path, url_obj.params, urllib.urlencode(qs_dict), url_obj.fragment))\n",
    "    self._driver.get(doc_url)  # jump to the page we want\n",
    "\n",
    "    # qs_dict['RELEVANCE'] = 'BOOLEAN'  # doesnt seem to work\n",
    "    # http://www.lexisnexis.com/lnacui2api/results/docview/docview.do?docLinkInd=true&risb=21_T21153102977&format=GNBFI&sort=RELEVANCE&startDocNo=1&resultsUrlKey=29_T21153102981&cisb=22_T21153102980&treeMax=true&treeWidth=0&csi=6318&docNo=1\n",
    "\n",
    "    for doc_index in xrange(start_from, documents_count + 1):\n",
    "      self._switch_to_frame('content', in_iframe=False)\n",
    "      page_content = self._driver.page_source\n",
    "      yield (page_content, (doc_index, documents_count))\n",
    "\n",
    "      self._switch_to_frame('navigation', in_iframe=False)\n",
    "      next_page_elem = self._wait_for_element('//img[@title=\\'View next document\\']', raise_error=False)\n",
    "      if next_page_elem is None:\n",
    "        if doc_index != documents_count:\n",
    "          raise Exception('Next page icon could not be found: doc_index={}, documents_count={}'.format(doc_index, documents_count))\n",
    "      else: next_page_elem.click()\n",
    "    #end while\n",
    "  #end def\n",
    "\n",
    "  def _switch_to_frame(self, frame_name, in_iframe=True):\n",
    "    self._driver.switch_to.default_content()\n",
    "\n",
    "    if in_iframe:\n",
    "      frame = self._safe_wait(expected_conditions.frame_to_be_available_and_switch_to_it('mainFrame'))\n",
    "      if not frame: raise SwitchFrameException(frame_name)\n",
    "    #end if\n",
    "\n",
    "    try:\n",
    "      if frame_name == 'main': return frame\n",
    "      elif frame_name == 'results': frame = self._wait_for_element('//frame[@title=\\'Results Content Frame\\']')\n",
    "      elif frame_name == 'navigation': frame = self._wait_for_element('//frame[@title=\\'Results Navigation Frame\\']')\n",
    "      elif frame_name == 'content': frame = self._wait_for_element('//frame[@title=\\'Results Document Content Frame\\']')\n",
    "    except selenium.common.exceptions.TimeoutException:\n",
    "      raise SwitchFrameException(frame_name)\n",
    "\n",
    "    self._safe_wait(expected_conditions.frame_to_be_available_and_switch_to_it(frame))\n",
    "\n",
    "    return frame\n",
    "  #end def\n",
    "\n",
    "  def _safe_wait(self, poll_func):\n",
    "    try: return self._short_wait.until(poll_func)\n",
    "    except selenium.common.exceptions.TimeoutException: return None\n",
    "  #end def\n",
    "\n",
    "  def _wait_for_element(self, xpath, raise_error=True):\n",
    "    elem = self._safe_wait(expected_conditions.presence_of_element_located((selenium.webdriver.common.by.By.XPATH, xpath)))\n",
    "    if raise_error and elem is None: raise selenium.common.exceptions.TimeoutException(msg='XPath \\'{}\\' presence wait timeout.'.format(xpath))\n",
    "    return elem\n",
    "  #end def\n",
    "#end class\n",
    "\n",
    "\n",
    "class SwitchFrameException(Exception):\n",
    "  \"\"\"\n",
    "  Exception class when we are unable to load the require page properly.\n",
    "  This is usually due to\n",
    "  #. Page taking too long to load. This happens sometimes when loading LexisNexis for the first time.\n",
    "  #. Improper page loading.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, frame_name): self.frame_name = frame_name\n",
    "\n",
    "  def __str__(self): return u'Exception while switching to frame \\'{}\\'.'.format(self.frame_name)\n",
    "#end class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
